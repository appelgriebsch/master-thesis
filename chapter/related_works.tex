%!TEX root = ../MasterThesis.tex

\chapter{Related Works}
\label{cha:related_works}

The study of Pritikana Sen et al. starts with an introduction to the subject of \gls{E-commerce} and specifies possible types of it. It further shows the benefits of \gls{E-commerce} (e.g.\ the global reach of Web shops) as well as its limitations. Here it mentioned explicitly the security of the system and the communication protocols used. The paper lists the relevant stakeholders of an \gls{E-commerce} transaction and describes the credit card payment process in detail. It concludes with an analysis of the security features of a Web shop and shows that those are not limited to technical aspects alone, but always includes the consumer and his behavior on the Internet \citep{sen2015study}. \\

The paper from Sobko defines non-cash transactions and shows ways how fraudsters try to cheat the system. It starts with a classification of non-cash payments including credit and debit cards that are handed out by financial institutions to individuals. The authors also note possible ways to trick an individual with the objective to get access to credit card information such as phishing and skimming. They explain that once a transaction has been successfully executed with a stolen credit card, the information about it will be sold on the black market to other fraudsters, who will then use the same credit card to make additional purchases. Further on the paper discusses the impact of fraudulent transactions for the merchants and credit card owners as well as shows technological advances and regulations that have been developed to protect them against non-cash frauds \citep{sobko2014fraud}. \\

The research of Priya J. Rana et al. shows possible frauds in \gls{E-commerce} and how they can be detected with current fraud prevention systems. They explain different implementations of fraud detection algorithms, which range from simple rule-based filtering to score-based solution using fuzzy logic. They conclude that general systems in use can cover up to 80\% of fraudulent transactions at manageable efforts and costs. More coverage can be achieved by combining existing solutions with information of the card owners profile, which would introduce credit card usages patterns into the analysis. Still this latter solution is very expensive to implement and operate \citep{rana2015survey}. \\

The paper from Carvalho et al. looks into the financial crime investigation process by using banking frauds as example. It shows that the investigation of them is a very complex task that needs further collaboration between experts. Still just sharing the information will not be enough as a common understanding of the different aspects and terms is required. Therefore they state that finding a common language to exchange information is very important for the success of the investigation. Based on this finding the paper also develops an ontology to describe the domain of banking fraud investigation. It elaborates on the objects and their relations in detail and shows that reusing concepts and terms from existing vocabularies can be helpful when designing an own ontology. The paper concludes that semantic technologies can have a positive impact on the crime investigation as they are providing basic reasoning capabilities on the data sets as well as support the combination of information from different sources. These features will allow a crime investigator from a law enforcement agency to inspect and analyze more complex information with the help of \gls{IT} systems. Finally the paper considers semantic technology to be very important in future cybercrime inspections \citep{carvalhoapplying}. \\

The seminal paper ``Linked data-the story so far'' explains the fundamental concepts, approaches and technologies to share data on the Web. It shows how a \gls{RDF} data set should be used to publish structured data on the Web and provide rules how these resources should be described. Additionally it discusses the commonly used vocabularies available on the Web. It also explains ways how to link together different resources on the Internet. After describing different kinds of applications that are possible with the technologies shown it gives an outlook of future research, which also states the aspects of schema mapping and data fusion as possible challenge. Another one in the area of Linked data are possible privacy violations that might come up when information from different sources will be combined. As conclusion the paper sees the Linked data approach as intermediate step to a Semantic Web, because it also follows established Web standards such as \gls{RDF}, \gls{RDFS} and \gls{SPARQL}, but it uses a more pragmatic approach by getting rid of all the complexities involved when having to create, maintain and use large ontologies in \gls{OWL} \citep{bizer2009linked}. \\

Different ways to publish semantic data on the Web have been analyzed by Laurens Rietveld et al. They show that current approaches range from simple data dumps of complete \gls{RDF} data sets to query endpoints using the \gls{SPARQL} protocol and query language. As a conclusion they state that the flexible approach of hosting \gls{SPARQL} endpoints is generally not working for open access on the Internet, but is instead more suitable for internal data collection and analysis. This is due to the enormous overhead of a \gls{SPARQL} server both in memory and CPU consumption if it has to deal with a large \gls{RDF} data set provided to a large number of possible users (on the Web). The solution, which has been evolved in the research paper, is utilizing approaches called ``Linked Data documents'' and ``Triple Pattern Fragments''. The former one is providing subsets of a \gls{RDF} data set optimized for specific subjects or objects and allow focused querying a \gls{RDF} data set. The latter one tries to move parts of the processing of querying a large scale \gls{RDF} data set from the server to the clients and builds upon the ideas of the ``Linked Data documents''. As a result of the paper new approaches are needed for offering \gls{RDF} data sets on the Web, which are optimized for querying and processing large scale \gls{RDF} data sets, and make better use of the processing capabilities of clients \citep{rietveld2015linked}. \\

The need for a \gls{RDF} vocabulary to express products and offerings on the Internet was first mentioned and described by Martin Hepp. The author is also the founder of the GoodRelations vocabulary, which has been explained in detail in this paper. After showing possible use case scenarios for such as ontology on the Web the author elaborates over the available entities and their meanings. Interestingly the author states that he has restricted usage of more expressive \gls{OWL} axioms in the GoodRelations vocabulary due to the limited availability of full-featured \gls{OWL} reasoners. By focusing on \gls{RDFS} constraints less functionality is required for the processing engine of the \gls{RDF} data sets. The paper closes with examples of using the vocabulary in the \gls{E-commerce} scenario, and its possible future development for \gls{B2B} service integrations \citep{hepp2008goodrelations}.

- ``Schema.org: Evolution of structured data on the web'' \citep{guha2016schema} \\
- ``Leveraging WebRTC for P2P content distribution in web browsers'' \citep{vogt2013leveraging} \\
- ``Content-centric user networks: WebRTC as a path to name-based publishing'' \citep{vogt2013content}

% chapter related works (end)
